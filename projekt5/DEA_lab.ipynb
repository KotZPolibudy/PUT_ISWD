{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pulp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_csv('inputs.csv', index_col=0, delimiter=';')\n",
    "outputs = pd.read_csv('outputs.csv', index_col=0, delimiter=';')\n",
    "samples = pd.read_csv('samples_homework.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_scores = {}\n",
    "reference_units = {}\n",
    "adjustments = {}\n",
    "super_efficiency_scores = {}\n",
    "cross_efficiency_scores = {DMU: [] for DMU in inputs.index}\n",
    "expected_efficiency = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency for WAW: 1.00\n",
      "Super Efficiency for WAW: 0.44\n",
      "Expected Efficiency for WAW: 1.00\n",
      "Efficiency for KRK: 1.00\n",
      "Super Efficiency for KRK: 0.89\n",
      "Expected Efficiency for KRK: 1.00\n",
      "Efficiency for KAT: 0.59\n",
      "Super Efficiency for KAT: 1.69\n",
      "Adjustments for KAT:\n",
      "  i1: reduce to 1.47\n",
      "  i2: reduce to 13.08\n",
      "  i3: reduce to 23.46\n",
      "  i4: reduce to 6.10\n",
      "Reference Units for KAT:\n",
      "  KRK: 0.00\n",
      "  WRO: 1.23\n",
      "  GDN: 0.27\n",
      "Expected Efficiency for KAT: 0.59\n",
      "Efficiency for WRO: 1.00\n",
      "Super Efficiency for WRO: 0.96\n",
      "Expected Efficiency for WRO: 1.00\n",
      "Efficiency for POZ: 0.80\n",
      "Super Efficiency for POZ: 1.25\n",
      "Adjustments for POZ:\n",
      "  i1: reduce to 0.30\n",
      "  i2: reduce to 2.00\n",
      "  i3: reduce to 4.80\n",
      "  i4: reduce to 2.07\n",
      "Reference Units for POZ:\n",
      "  WAW: 0.05\n",
      "  KRK: 0.07\n",
      "  WRO: 0.20\n",
      "  GDN: 0.16\n",
      "Expected Efficiency for POZ: 0.80\n",
      "Efficiency for LCJ: 0.30\n",
      "Super Efficiency for LCJ: 3.33\n",
      "Adjustments for LCJ:\n",
      "  i1: reduce to 0.42\n",
      "  i2: reduce to 9.22\n",
      "  i3: reduce to 16.80\n",
      "  i4: reduce to 3.43\n",
      "Reference Units for LCJ:\n",
      "  GDN: 0.16\n",
      "  BZG: 0.06\n",
      "Expected Efficiency for LCJ: 0.30\n",
      "Efficiency for GDN: 1.00\n",
      "Super Efficiency for GDN: 0.50\n",
      "Expected Efficiency for GDN: 1.00\n",
      "Efficiency for SZZ: 0.27\n",
      "Super Efficiency for SZZ: 3.69\n",
      "Adjustments for SZZ:\n",
      "  i1: reduce to 0.51\n",
      "  i2: reduce to 7.29\n",
      "  i3: reduce to 18.74\n",
      "  i4: reduce to 1.43\n",
      "Reference Units for SZZ:\n",
      "  WAW: 0.00\n",
      "  GDN: 0.15\n",
      "  BZG: 0.06\n",
      "Expected Efficiency for SZZ: 0.27\n",
      "Efficiency for BZG: 1.00\n",
      "Super Efficiency for BZG: 0.57\n",
      "Expected Efficiency for BZG: 1.00\n",
      "Efficiency for RZE: 0.41\n",
      "Super Efficiency for RZE: 2.44\n",
      "Adjustments for RZE:\n",
      "  i1: reduce to 0.35\n",
      "  i2: reduce to 3.54\n",
      "  i3: reduce to 6.68\n",
      "  i4: reduce to 2.16\n",
      "Reference Units for RZE:\n",
      "  WRO: 0.12\n",
      "  GDN: 0.05\n",
      "  BZG: 0.03\n",
      "Expected Efficiency for RZE: 0.41\n",
      "Efficiency for IEG: 0.26\n",
      "Super Efficiency for IEG: 3.87\n",
      "Adjustments for IEG:\n",
      "  i1: reduce to 0.07\n",
      "  i2: reduce to 9.61\n",
      "  i3: reduce to 62.29\n",
      "  i4: reduce to 2.94\n",
      "Reference Units for IEG:\n",
      "  GDN: 0.03\n",
      "Expected Efficiency for IEG: 0.26\n"
     ]
    }
   ],
   "source": [
    "#  Calculate efficiency and super-efficiency for each DMU\n",
    "for DMUo in inputs.index:\n",
    "    problem = LpProblem(f\"Efficiency_{DMUo}\", LpMinimize)\n",
    "    lambdas = LpVariable.dicts(\"Lambda\", (i for i in inputs.index), lowBound=0)\n",
    "    theta = LpVariable(\"theta\", lowBound=0, upBound=1)\n",
    "\n",
    "    problem += theta\n",
    "\n",
    "    for input_metric in inputs.columns:\n",
    "        problem += lpSum([lambdas[i] * inputs.loc[i, input_metric] for i in inputs.index]) <= theta * inputs.loc[DMUo, input_metric]\n",
    "\n",
    "    for output_metric in outputs.columns:\n",
    "        problem += lpSum([lambdas[i] * outputs.loc[i, output_metric] for i in inputs.index]) >= outputs.loc[DMUo, output_metric]\n",
    "\n",
    "    problem.solve(PULP_CBC_CMD(msg=False))\n",
    "\n",
    "    if LpStatus[problem.status] == 'Optimal':\n",
    "        efficiency_score = value(theta)\n",
    "        efficiency_scores[DMUo] = efficiency_score\n",
    "\n",
    "        if efficiency_score < 1:\n",
    "            reference_units[DMUo] = {}\n",
    "            adjustments[DMUo] = {}\n",
    "            for i in inputs.index:\n",
    "                if lambdas[i].varValue > 0:\n",
    "                    reference_units[DMUo][i] = lambdas[i].varValue\n",
    "\n",
    "            for input_metric in inputs.columns:\n",
    "                optimal_input = sum(lambdas[i].varValue * inputs.loc[i, input_metric] for i in inputs.index)\n",
    "                adjustments[DMUo][input_metric] = inputs.loc[DMUo, input_metric] - optimal_input\n",
    "\n",
    "    else:\n",
    "        print(f\"Problem for {DMUo} is not solvable\")\n",
    "    \n",
    "    # Superefektywność\n",
    "    super_problem = LpProblem(f\"SuperEfficiency_{DMUo}\", LpMinimize)\n",
    "    super_lambdas = LpVariable.dicts(\"SuperLambda\", (i for i in inputs.index if i != DMUo), lowBound=0)\n",
    "    super_theta = LpVariable(\"super_theta\", lowBound=0)\n",
    "\n",
    "    super_problem += super_theta\n",
    "    for input_metric in inputs.columns:\n",
    "        super_problem += lpSum([super_lambdas[i] * inputs.loc[i, input_metric] for i in inputs.index if i != DMUo]) <= super_theta * inputs.loc[DMUo, input_metric]\n",
    "    for output_metric in outputs.columns:\n",
    "        super_problem += lpSum([super_lambdas[i] * outputs.loc[i, output_metric] for i in inputs.index if i != DMUo]) >= outputs.loc[DMUo, output_metric]\n",
    "    \n",
    "    super_problem.solve(PULP_CBC_CMD(msg=False))\n",
    "    if LpStatus[super_problem.status] == 'Optimal':\n",
    "        super_efficiency_scores[DMUo] = 1 / value(super_theta)\n",
    "\n",
    "# Calculate cross-efficiency and expected efficiency\n",
    "for DMUo in inputs.index:\n",
    "    all_efficiencies = []\n",
    "    for index, sample in samples.iterrows():\n",
    "        problem = LpProblem(f\"SampleEfficiency_{DMUo}_{index}\", LpMinimize)\n",
    "        lambdas = LpVariable.dicts(\"Lambda\", (i for i in inputs.index), lowBound=0)\n",
    "        theta = LpVariable(\"theta\", lowBound=0, upBound=1)\n",
    "        \n",
    "        problem += theta\n",
    "        for input_metric in inputs.columns:\n",
    "            problem += lpSum([lambdas[i] * inputs.loc[i, input_metric] * sample[input_metric] for i in inputs.index]) <= theta * inputs.loc[DMUo, input_metric] * sample[input_metric]\n",
    "        for output_metric in outputs.columns:\n",
    "            problem += lpSum([lambdas[i] * outputs.loc[i, output_metric] * sample[output_metric] for i in inputs.index]) >= outputs.loc[DMUo, output_metric] * sample[output_metric]\n",
    "\n",
    "        problem.solve(PULP_CBC_CMD(msg=False))\n",
    "        if LpStatus[problem.status] == 'Optimal':\n",
    "            all_efficiencies.append(value(theta))\n",
    "\n",
    "    cross_efficiency_scores[DMUo].extend(all_efficiencies)\n",
    "    expected_efficiency[DMUo] = np.mean(all_efficiencies)\n",
    "\n",
    "\n",
    "# Display the results\n",
    "for airport, efficiency in efficiency_scores.items():\n",
    "    print(f\"Efficiency for {airport}: {efficiency:.2f}\")\n",
    "    if airport in super_efficiency_scores:\n",
    "        print(f\"Super Efficiency for {airport}: {super_efficiency_scores[airport]:.2f}\")\n",
    "    if airport in adjustments:\n",
    "        print(f\"Adjustments for {airport}:\")\n",
    "        for metric, value in adjustments[airport].items():\n",
    "            print(f\"  {metric}: reduce to {value:.2f}\")\n",
    "    if airport in reference_units:\n",
    "        print(f\"Reference Units for {airport}:\")\n",
    "        for unit, value in reference_units[airport].items():\n",
    "            print(f\"  {unit}: {value:.2f}\")\n",
    "    print(f\"Expected Efficiency for {airport}: {expected_efficiency[airport]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001B[39m, in \u001B[36mimport_optional_dependency\u001B[39m\u001B[34m(name, extra, errors, min_version)\u001B[39m\n\u001B[32m    134\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m135\u001B[39m     module = \u001B[43mimportlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001B[39m, in \u001B[36mimport_module\u001B[39m\u001B[34m(name, package)\u001B[39m\n\u001B[32m     89\u001B[39m         level += \u001B[32m1\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1387\u001B[39m, in \u001B[36m_gcd_import\u001B[39m\u001B[34m(name, package, level)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1360\u001B[39m, in \u001B[36m_find_and_load\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1324\u001B[39m, in \u001B[36m_find_and_load_unlocked\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'tabulate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 43\u001B[39m\n\u001B[32m     40\u001B[39m cross_efficiency_matrix.to_csv(\u001B[33m'\u001B[39m\u001B[33mcross_efficiency_matrix.csv\u001B[39m\u001B[33m'\u001B[39m, index=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     42\u001B[39m \u001B[38;5;66;03m# Format the table for display\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m table_format = \u001B[43mcross_efficiency_matrix\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreset_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_markdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[38;5;28mprint\u001B[39m(table_format)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001B[39m, in \u001B[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) > num_allow_args:\n\u001B[32m    328\u001B[39m     warnings.warn(\n\u001B[32m    329\u001B[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001B[32m    330\u001B[39m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m    331\u001B[39m         stacklevel=find_stack_level(),\n\u001B[32m    332\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m333\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:2983\u001B[39m, in \u001B[36mDataFrame.to_markdown\u001B[39m\u001B[34m(self, buf, mode, index, storage_options, **kwargs)\u001B[39m\n\u001B[32m   2981\u001B[39m kwargs.setdefault(\u001B[33m\"\u001B[39m\u001B[33mtablefmt\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mpipe\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   2982\u001B[39m kwargs.setdefault(\u001B[33m\"\u001B[39m\u001B[33mshowindex\u001B[39m\u001B[33m\"\u001B[39m, index)\n\u001B[32m-> \u001B[39m\u001B[32m2983\u001B[39m tabulate = \u001B[43mimport_optional_dependency\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtabulate\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   2984\u001B[39m result = tabulate.tabulate(\u001B[38;5;28mself\u001B[39m, **kwargs)\n\u001B[32m   2985\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m buf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001B[39m, in \u001B[36mimport_optional_dependency\u001B[39m\u001B[34m(name, extra, errors, min_version)\u001B[39m\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[32m    137\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m errors == \u001B[33m\"\u001B[39m\u001B[33mraise\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m138\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[32m    139\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    141\u001B[39m \u001B[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001B[39;00m\n",
      "\u001B[31mImportError\u001B[39m: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pulp import LpProblem, LpVariable, lpSum, LpMinimize, PULP_CBC_CMD, LpStatus, value\n",
    "\n",
    "# Assuming the necessary data frames 'inputs' and 'outputs' are already defined\n",
    "samples = pd.read_csv('samples_homework.csv')\n",
    "cross_efficiency_matrix = pd.DataFrame(index=inputs.index, columns=inputs.index)\n",
    "\n",
    "# Calculate cross-efficiency for each DMU\n",
    "for DMUo in inputs.index:\n",
    "    for DMU in inputs.index:\n",
    "        if DMU != DMUo:\n",
    "            problem = LpProblem(f\"CrossEfficiency_{DMUo}_using_{DMU}\", LpMinimize)\n",
    "            lambdas = LpVariable.dicts(\"Lambda\", (i for i in inputs.index), lowBound=0)\n",
    "            theta = LpVariable(\"theta\", lowBound=0, upBound=1)\n",
    "\n",
    "            problem += theta\n",
    "\n",
    "            for input_metric in inputs.columns:\n",
    "                problem += lpSum([lambdas[i] * inputs.loc[i, input_metric] for i in inputs.index]) <= theta * inputs.loc[DMUo, input_metric]\n",
    "\n",
    "            for output_metric in outputs.columns:\n",
    "                problem += lpSum([lambdas[i] * outputs.loc[i, output_metric] for i in inputs.index]) >= outputs.loc[DMUo, output_metric]\n",
    "\n",
    "            problem.solve(PULP_CBC_CMD(msg=False))\n",
    "\n",
    "            if LpStatus[problem.status] == 'Optimal':\n",
    "                cross_efficiency_matrix.loc[DMUo, DMU] = value(theta)\n",
    "        else:\n",
    "            cross_efficiency_matrix.loc[DMUo, DMU] = 1  # Self-evaluation is always 1\n",
    "\n",
    "# Calculate average cross-efficiency\n",
    "cross_efficiency_matrix['CRavg'] = cross_efficiency_matrix.mean(axis=1)\n",
    "\n",
    "# # Display the cross-efficiency matrix\n",
    "# print(\"Cross-Efficiency Matrix:\")\n",
    "# print(cross_efficiency_matrix)\n",
    "\n",
    "# Save the cross-efficiency matrix to a CSV file (optional)\n",
    "cross_efficiency_matrix.to_csv('cross_efficiency_matrix.csv', index=True)\n",
    "\n",
    "# Format the table for display\n",
    "table_format = cross_efficiency_matrix.reset_index().to_markdown(index=False)\n",
    "print(table_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for reference units (HCU)\n",
    "reference_units_df = pd.DataFrame(reference_units).fillna(0)\n",
    "\n",
    "# Calculate HCU values\n",
    "hcu_values = {}\n",
    "for DMU, refs in reference_units.items():\n",
    "    hcu_values[DMU] = {}\n",
    "    for input_metric in inputs.columns:\n",
    "        hcu_values[DMU][input_metric] = sum(refs[i] * inputs.loc[i, input_metric] for i in refs)\n",
    "\n",
    "hcu_df = pd.DataFrame(hcu_values).T\n",
    "\n",
    "# Ensure all DMUs are included\n",
    "for DMU in inputs.index:\n",
    "    if DMU not in hcu_df.index:\n",
    "        hcu_df.loc[DMU] = np.nan\n",
    "    if DMU not in adjustments_df.index:\n",
    "        adjustments_df.loc[DMU] = np.nan\n",
    "\n",
    "# Fill NaN values with 0 for effective DMUs\n",
    "hcu_df = hcu_df.fillna(0)\n",
    "adjustments_df = (inputs - hcu_df).fillna(0)\n",
    "\n",
    "# Ensure that the DataFrames have the same columns\n",
    "hcu_df = hcu_df[inputs.columns]\n",
    "adjustments_df = adjustments_df[inputs.columns]\n",
    "\n",
    "# Combine HCU and Adjustments into a single DataFrame\n",
    "combined_df = pd.concat([hcu_df, adjustments_df], axis=1)\n",
    "\n",
    "# Rename columns to match the format\n",
    "new_columns = [f'HCU_{col}' for col in hcu_df.columns] + [f'Poprawki_{col}' for col in adjustments_df.columns]\n",
    "combined_df.columns = new_columns\n",
    "\n",
    "# # Display the combined DataFrame\n",
    "# print(\"Combined HCU and Adjustments Table:\")\n",
    "# print(combined_df)\n",
    "\n",
    "# Save the combined table to a CSV file (optional)\n",
    "combined_df.to_csv('hcu_and_adjustments.csv', index=True)\n",
    "\n",
    "# Format the table for display\n",
    "table_format = combined_df.reset_index().to_markdown(index=False)\n",
    "print(table_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume efficiency_scores, super_efficiency_scores, and expected_efficiency are dictionaries with the necessary data\n",
    "\n",
    "# Create DataFrame for ranking\n",
    "results_df = pd.DataFrame({\n",
    "    'Efficiency': pd.Series(efficiency_scores),\n",
    "    'SuperEfficiency': pd.Series(super_efficiency_scores),\n",
    "    'ExpectedEfficiency': pd.Series(expected_efficiency)\n",
    "})\n",
    "\n",
    "# Rank units\n",
    "results_df['EfficiencyRank'] = results_df['Efficiency'].rank(ascending=False)\n",
    "results_df['SuperEfficiencyRank'] = results_df['SuperEfficiency'].rank(ascending=False)\n",
    "results_df['ExpectedEfficiencyRank'] = results_df['ExpectedEfficiency'].rank(ascending=False)\n",
    "\n",
    "# Display the rankings\n",
    "results_df.sort_values(by='EfficiencyRank', inplace=True)\n",
    "print(\"Rankings based on Efficiency, SuperEfficiency, and ExpectedEfficiency:\")\n",
    "print(results_df)\n",
    "\n",
    "# Analyze the ranking consistency\n",
    "results_df['EfficiencyRank'] = results_df['EfficiencyRank'].astype(int)\n",
    "results_df['SuperEfficiencyRank'] = results_df['SuperEfficiencyRank'].astype(int)\n",
    "results_df['ExpectedEfficiencyRank'] = results_df['ExpectedEfficiencyRank'].astype(int)\n",
    "\n",
    "# Calculate Spearman rank correlation to check consistency\n",
    "efficiency_super_corr = results_df[['EfficiencyRank', 'SuperEfficiencyRank']].corr(method='spearman').iloc[0, 1]\n",
    "efficiency_expected_corr = results_df[['EfficiencyRank', 'ExpectedEfficiencyRank']].corr(method='spearman').iloc[0, 1]\n",
    "super_expected_corr = results_df[['SuperEfficiencyRank', 'ExpectedEfficiencyRank']].corr(method='spearman').iloc[0, 1]\n",
    "\n",
    "print(f\"Spearman Rank Correlation between Efficiency and SuperEfficiency: {efficiency_super_corr:.2f}\")\n",
    "print(f\"Spearman Rank Correlation between Efficiency and ExpectedEfficiency: {efficiency_expected_corr:.2f}\")\n",
    "print(f\"Spearman Rank Correlation between SuperEfficiency and ExpectedEfficiency: {super_expected_corr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for ranking\n",
    "results_df = pd.DataFrame({\n",
    "    'Efficiency': pd.Series(efficiency_scores),\n",
    "    'SuperEfficiency': pd.Series(super_efficiency_scores),\n",
    "    'ExpectedEfficiency': pd.Series(expected_efficiency)\n",
    "})\n",
    "\n",
    "# Rank units\n",
    "results_df['EfficiencyRank'] = results_df['Efficiency'].rank(ascending=False)\n",
    "results_df['SuperEfficiencyRank'] = results_df['SuperEfficiency'].rank(ascending=False)\n",
    "results_df['ExpectedEfficiencyRank'] = results_df['ExpectedEfficiency'].rank(ascending=False)\n",
    "\n",
    "# Sort DataFrame by ranks\n",
    "efficiency_ranking = results_df.sort_values(by='EfficiencyRank').index.tolist()\n",
    "super_efficiency_ranking = results_df.sort_values(by='SuperEfficiencyRank').index.tolist()\n",
    "expected_efficiency_ranking = results_df.sort_values(by='ExpectedEfficiencyRank').index.tolist()\n",
    "\n",
    "# Format rankings into the desired output\n",
    "super_efficiency_str = \" ≻ \".join(super_efficiency_ranking)\n",
    "average_efficiency_str = \" ≻ \".join(efficiency_ranking)\n",
    "expected_efficiency_str = \" ≻ \".join(expected_efficiency_ranking)\n",
    "\n",
    "# Print the formatted rankings\n",
    "print(f\"Superefektywność: {super_efficiency_str}\")\n",
    "print(f\"Średnia efektywność krzyżowa: {average_efficiency_str}\")\n",
    "print(f\"Oczekiwana wartość efektywności: {expected_efficiency_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller bins for better visualization\n",
    "bins = np.linspace(0, 1, 6)  # Adjust the number of bins to match the table\n",
    "bin_labels = ['[0-0.2]', '[0.2-0.4]', '[0.4-0.6]', '[0.6-0.8]', '[0.8-1.0]']\n",
    "\n",
    "# Calculate efficiency distributions\n",
    "efficiency_distributions = {DMU: np.histogram(cross_efficiency_scores[DMU], bins=bins)[0] for DMU in inputs.index}\n",
    "\n",
    "# Create DataFrame for distribution\n",
    "distribution_df = pd.DataFrame(efficiency_distributions).T\n",
    "distribution_df.columns = bin_labels\n",
    "\n",
    "# Add expected efficiency column\n",
    "distribution_df['EE'] = distribution_df.index.map(expected_efficiency)\n",
    "\n",
    "# Display the distribution\n",
    "print(\"Efficiency Distribution for Each DMU:\")\n",
    "print(distribution_df)\n",
    "\n",
    "# Plot the distributions for each DMU\n",
    "fig, axs = plt.subplots(len(inputs.index), 1, figsize=(10, len(inputs.index)*3), sharex=True)\n",
    "\n",
    "for idx, DMU in enumerate(inputs.index):\n",
    "    axs[idx].bar(distribution_df.columns[:-1], distribution_df.loc[DMU][:-1])  # Exclude 'EE' column for plotting\n",
    "    axs[idx].set_title(f'Efficiency Distribution for {DMU}')\n",
    "    axs[idx].set_ylabel('Count')\n",
    "    axs[idx].set_ylim(0, max(distribution_df.max()))\n",
    "    axs[idx].set_xticks(range(len(bin_labels)))\n",
    "    axs[idx].set_xticklabels(bin_labels)\n",
    "\n",
    "plt.xlabel('Efficiency Bins')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combined histogram for all DMUs\n",
    "plt.figure(figsize=(12, 8))\n",
    "for DMU, efficiencies in cross_efficiency_scores.items():\n",
    "    plt.hist(efficiencies, bins=bins, alpha=0.5, label=DMU)\n",
    "plt.xlabel('Efficiency')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Efficiency Distribution Across All DMUs')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Efficiency Distribution Table\", dataframe=distribution_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iswd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
